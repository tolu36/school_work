{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Using a Manhattan distance metric with k nearest neighbor classification with k=3, k=5 and k=7, classify the following\n",
    "universities as public or private and determine the number of errors in classification for each different value of k.\n",
    "Assume that the ordinal data is NOT to be scaled between the minimum and maximum values when computing an\n",
    "overall distance for all attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = pd.read_csv('assign2 data1.JPG.csv')\n",
    "df_train2 = pd.read_csv('assign2 data3.JPG.csv')\n",
    "\n",
    "df_test1 = pd.read_csv('assign2 data2.csv')\n",
    "df_test2 = pd.read_csv('assign2 data4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the target from both the train and test dataset\n",
    "df_train1['Private/Public']=np.where(df_train1['Private/Public']=='private',1,0)\n",
    "df_test1['Private/Public']=np.where(df_test1['Private/Public']=='private',1,0)\n",
    "df_train1x = df_train1.loc[:, df_train1.columns != 'Private/Public']\n",
    "df_train1y=df_train1['Private/Public']\n",
    "df_test1x = df_test1.loc[:, df_test1.columns != 'Private/Public']\n",
    "df_test1y=df_test1['Private/Public']\n",
    "\n",
    "# encoding the categorical variables\n",
    "uni_name = list(set(list(df_train1['University Name'].unique()) + list(df_test1['University Name'].unique())))\n",
    "uni_state = list(set(list(df_train1['University State'].unique()) + list(df_test1['University State'].unique())))\n",
    "\n",
    "df_train1x[uni_name + uni_state]=0\n",
    "df_test1x[uni_name + uni_state]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the target from both the train and test dataset\n",
    "df_train1['Private/Public']=np.where(df_train1['Private/Public']=='private',1,0)\n",
    "df_test1['Private/Public']=np.where(df_test1['Private/Public']=='private',1,0)\n",
    "df_train1x = df_train1.loc[:, df_train1.columns != 'Private/Public']\n",
    "df_train1y=df_train1['Private/Public']\n",
    "df_test1x = df_test1.loc[:, df_test1.columns != 'Private/Public']\n",
    "df_test1y=df_test1['Private/Public']\n",
    "\n",
    "# encoding the categorical variables\n",
    "uni_name = list(set(list(df_train1['University Name'].unique()) + list(df_test1['University Name'].unique())))\n",
    "uni_state = list(set(list(df_train1['University State'].unique()) + list(df_test1['University State'].unique())))\n",
    "\n",
    "df_train1x[uni_name + uni_state]=0\n",
    "df_test1x[uni_name + uni_state]=0\n",
    "\n",
    "for i in range(1,6):\n",
    "    df_train1x[f'Academics (1 5)_{i}']=0\n",
    "    df_train1x.loc[df_train1x['Academics (1 5)']==i, [f'Academics (1 5)_{i}']]=1\n",
    "    df_train1x[f'Social (1 5)_{i}']=0\n",
    "    df_train1x.loc[df_train1x['Social (1 5)']==i, [f'Social (1 5)_{i}']]=1\n",
    "    df_train1x[f'Quality of Life_{i}']=0\n",
    "    df_train1x.loc[df_train1x['Quality of Life (1 5)']==i, [f'Quality of Life (1 5)_{i}']]=1\n",
    "    df_test1x[f'Academics (1 5)_{i}']=0\n",
    "    df_test1x.loc[df_test1x['Academics (1 5)']==i, [f'Academics (1 5)_{i}']]=1\n",
    "    df_test1x[f'Social (1 5)_{i}']=0\n",
    "    df_test1x.loc[df_test1x['Social (1 5)']==i, [f'Social (1 5)_{i}']]=1\n",
    "    df_test1x[f'Quality of Life_{i}']=0\n",
    "    df_test1x.loc[df_test1x['Quality of Life (1 5)']==i, [f'Quality of Life (1 5)_{i}']]=1\n",
    "\n",
    "for i in uni_name:\n",
    "    df_train1x.loc[df_train1x['University Name']==i, [i]]=1\n",
    "    df_test1x.loc[df_test1x['University Name']==i, [i]]=1\n",
    "\n",
    "for i in uni_state:\n",
    "    df_train1x.loc[df_train1x['University State']==i, [i]]=1\n",
    "    df_test1x.loc[df_test1x['University State']==i, [i]]=1\n",
    "\n",
    "df_train1x.fillna(0, inplace=True)\n",
    "df_test1x.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# knowing the SAT score range is between 200-800, I used a min and max scaling for the sat math and verbal scores.\n",
    "# scaling the numerical variables between 0 and 1\n",
    "for i in ['SAT verbal', 'SAT math']:\n",
    "    df_train1x[f'{i}_scaled'] = (df_train1x[i] - 200)/(800-200)\n",
    "    df_test1x[f'{i}_scaled'] = (df_test1x[i] - 200)/(800-200)\n",
    "\n",
    "# dropping the old categories after encoding\n",
    "df_train1x.drop(['University Name', 'University State', 'Academics (1 5)','Social (1 5)','Quality of Life (1 5)','SAT verbal', 'SAT math'], axis=1, inplace=True)\n",
    "df_test1x.drop(['University Name', 'University State', 'Academics (1 5)','Social (1 5)','Quality of Life (1 5)','SAT verbal', 'SAT math'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k = 3, the total errors =  2.0\n",
      "With k = 5, the total errors =  1.0\n",
      "With k = 7, the total errors =  3.0\n"
     ]
    }
   ],
   "source": [
    "# KNN algorithm \n",
    "k_values = [3,5,7]\n",
    "dist = np.zeros(len(df_test1x))\n",
    "errors = np.zeros(len(df_test1x))\n",
    "for k in k_values:\n",
    "    for i in range(len(df_test1x)):\n",
    "        # manhattan distance\n",
    "        dist = np.sum(abs(df_train1x - df_test1x.iloc[i,:]), axis=1)\n",
    "        sortIndex = np.argsort(dist)\n",
    "        bestLabels = df_train1y.loc[sortIndex[0:k]]\n",
    "        prediction = (sum(bestLabels) > k/2.0)*1.0\n",
    "        errors[i] = (df_test1y[i] != prediction)*1.0\n",
    "\n",
    "    print(f\"With k = {k}, the total errors = \", np.sum(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k = 3, the total errors =  2\n",
      "With k = 5, the total errors =  1\n",
      "With k = 7, the total errors =  3\n"
     ]
    }
   ],
   "source": [
    "# compared to the KNN used in the Sklearn package (this was done as a validation check).\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# for k in [3,5,7]:\n",
    "#     knn = KNeighborsClassifier(n_neighbors=k, p=1)\n",
    "#     knn.fit(df_train1x.to_numpy(), df_train1y.to_numpy())\n",
    "#     y_pred_test = knn.predict(df_test1x.to_numpy())\n",
    "#     errors = sum(df_test1y != y_pred_test)\n",
    "#     print(f\"With k = {k}, the total errors = \", errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above KNN algorithm we can see that optimal number neighbours is 5; as it had the lowest misclassification amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Assuming that all of the binary data can be treated as symmetric, use k nearest neighbor classification with k = 3, 5 and\n",
    "7, classify the following data for two different attributes – bladder inflammation (yes, no) and Nephritis (yes, no).\n",
    "Additionally, determine how many errors we would obtain for the two classification results for each value of k.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary encoding\n",
    "df_train2.replace({'yes':1, 'no':0},inplace=True)\n",
    "df_test2.replace({'yes':1, 'no':0}, inplace=True)\n",
    "\n",
    "# creating a joint target to capture the two different attributes of interest\n",
    "df_train2['target']=0\n",
    "df_test2['target']=0\n",
    "df_train2.loc[(df_train2['Nephritis']==1)&(df_train2['Bladder Inflamation']==1),['target']]=3\n",
    "df_train2.loc[(df_train2['Nephritis']==0)&(df_train2['Bladder Inflamation']==1),['target']]=2\n",
    "df_train2.loc[(df_train2['Nephritis']==1)&(df_train2['Bladder Inflamation']==0),['target']]=1\n",
    "df_test2.loc[(df_test2['Nephritis']==1)&(df_test2['Bladder Inflamation']==1),['target']]=3\n",
    "df_test2.loc[(df_test2['Nephritis']==0)&(df_test2['Bladder Inflamation']==1),['target']]=2\n",
    "df_test2.loc[(df_test2['Nephritis']==1)&(df_test2['Bladder Inflamation']==0),['target']]=1\n",
    "\n",
    "# scaling the patient temperature value to be between 0 and 1\n",
    "max_temp = max(set(list(df_train2['Temperature of Patient (°C)'].unique())+list(df_test2['Temperature of Patient (°C)'].unique())))\n",
    "min_temp = min(set(list(df_train2['Temperature of Patient (°C)'].unique())+list(df_test2['Temperature of Patient (°C)'].unique())))\n",
    "\n",
    "df_train2['temp_scaled'] = (df_train2['Temperature of Patient (°C)'] - min_temp)/(max_temp-min_temp)\n",
    "df_test2['temp_scaled'] = (df_test2['Temperature of Patient (°C)'] - min_temp)/(max_temp-min_temp)\n",
    "\n",
    "# splitting the predictor from the independent variables\n",
    "df_train2x= df_train2.drop(['Temperature of Patient (°C)','Patient Number','Nephritis','Bladder Inflamation','target'], axis=1)\n",
    "df_train2y=df_train2['target']\n",
    "df_test2x= df_test2.drop(['Temperature of Patient (°C)','Patient Number','Nephritis','Bladder Inflamation','target'], axis=1)\n",
    "df_test2y=df_test2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k = 3, the total errors =  1.0\n",
      "With k = 5, the total errors =  1.0\n",
      "With k = 7, the total errors =  3.0\n"
     ]
    }
   ],
   "source": [
    "# KNN algorithm \n",
    "k_values = [3,5,7]\n",
    "dist = np.zeros(len(df_test2x))\n",
    "errors = np.zeros(len(df_test2x))\n",
    "for k in k_values:\n",
    "    for i in range(len(df_test2x)):\n",
    "        # manhattan distance\n",
    "        dist = np.sum(abs(df_train2x - df_test2x.iloc[i,:]), axis=1)\n",
    "        sortIndex = np.argsort(dist)\n",
    "        bestLabels = df_train2y.loc[sortIndex[0:k]]\n",
    "        prediction = (sum(bestLabels) > k/2.0)*1.0\n",
    "        errors[i] = (df_test2y[i] != prediction)*1.0\n",
    "\n",
    "    print(f\"With k = {k}, the total errors = \", np.sum(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results the optimal value of k is 3 as it provides the least amount of misclassification and the least complicated model. The above results is based on the fact that the two attributes of interest were jointly classified; meaning there is one less feature used to train the model. This approach will be called method 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k = 3 and the attribute of interest is Nephritis, the total errors =  0.0\n",
      "With k = 5 and the attribute of interest is Nephritis, the total errors =  0.0\n",
      "With k = 7 and the attribute of interest is Nephritis, the total errors =  0.0\n",
      "With k = 3 and the attribute of interest is Bladder Inflamation, the total errors =  1.0\n",
      "With k = 5 and the attribute of interest is Bladder Inflamation, the total errors =  1.0\n",
      "With k = 7 and the attribute of interest is Bladder Inflamation, the total errors =  1.0\n"
     ]
    }
   ],
   "source": [
    "df_train2 = pd.read_csv('assign2 data3.JPG.csv')\n",
    "\n",
    "df_test2 = pd.read_csv('assign2 data4.csv')\n",
    "\n",
    "# binary encoding\n",
    "df_train2.replace({'yes':1, 'no':0},inplace=True)\n",
    "df_test2.replace({'yes':1, 'no':0}, inplace=True)\n",
    "\n",
    "\n",
    "# scaling the patient temperature value to be between 0 and 1\n",
    "max_temp = max(set(list(df_train2['Temperature of Patient (°C)'].unique())+list(df_test2['Temperature of Patient (°C)'].unique())))\n",
    "min_temp = min(set(list(df_train2['Temperature of Patient (°C)'].unique())+list(df_test2['Temperature of Patient (°C)'].unique())))\n",
    "\n",
    "df_train2['temp_scaled'] = (df_train2['Temperature of Patient (°C)'] - min_temp)/(max_temp-min_temp)\n",
    "df_test2['temp_scaled'] = (df_test2['Temperature of Patient (°C)'] - min_temp)/(max_temp-min_temp)\n",
    "\n",
    "# splitting the predictor from the independent variables\n",
    "for t in ['Nephritis','Bladder Inflamation']:\n",
    "    df_train2x= df_train2.drop(['Temperature of Patient (°C)','Patient Number',t], axis=1)\n",
    "    df_train2y=df_train2[t]\n",
    "    df_test2x= df_test2.drop(['Temperature of Patient (°C)','Patient Number',t], axis=1)\n",
    "    df_test2y=df_test2[t]\n",
    "    \n",
    "    # KNN algorithm \n",
    "    k_values = [3,5,7]\n",
    "    dist = np.zeros(len(df_test2x))\n",
    "    errors = np.zeros(len(df_test2x))\n",
    "    for k in k_values:\n",
    "        for i in range(len(df_test2x)):\n",
    "            # manhattan distance\n",
    "            dist = np.sum(abs(df_train2x - df_test2x.iloc[i,:]), axis=1)\n",
    "            sortIndex = np.argsort(dist)\n",
    "            bestLabels = df_train2y.loc[sortIndex[0:k]]\n",
    "            prediction = (sum(bestLabels) > k/2.0)*1.0\n",
    "            errors[i] = (df_test2y[i] != prediction)*1.0\n",
    "\n",
    "        print(f\"With k = {k} and the attribute of interest is {t}, the total errors = \", np.sum(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we classify the each attribute one at a time we see the classification accuracy increases. The addition of either Nephritis or Bladder Inflamation has helped the model performance. Particularly, when we include Bladder Inflamation as a feature when classifying Nephritis; in this scenario there is no misclassification error at any value of k.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30f0092c9ddbd796e6141aacd5c6fb3704c1ea2a2ccd09084af215b63610637b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
